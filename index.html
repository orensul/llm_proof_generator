<!DOCTYPE html>
<html>
<head>
  <!-- (Meta tags and other head elements remain unchanged) -->
  <title> Toward Reliable Proof Generation with LLMs </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  <!-- Hero section -->
 <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            Toward Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/oren-sultan-93039146/" target="_blank">Oren Sultan</a>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/eitan-stern-a98043208/" target="_blank">Eitan Stern</a>,</span>
            <span class="author-block">
              <a href="http://www.hyadatalab.com/" target="_blank">Dafna Shahaf</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <b>The Hebrew University of Jerusalem</b><br>
            </span>
            <br>
<!--            <span class="author-block">-->
<!--              <b>EMNLP 2024 (Main Conference, Industry Track)</b>-->
<!--            </span>-->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2505.14479" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/orensul/LLMs_proof_generation" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.14479" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

<!--              <span class="link-block">-->
<!--              <a href="https://www.orensultan.com/files/posters/AIRecolorPoster.pdf" target="_blank"-->
<!--                class="external-link button is-normal is-rounded is-dark">-->
<!--                <span class="icon">-->
<!--                  <i class="fas fa-file-pdf"></i>-->
<!--                </span>-->
<!--                <span>Poster</span>-->
<!--              </a>-->
<!--            </span>-->

<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=wdGOYrtm1Oc" target="_blank"-->
<!--                  class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                    <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Teaser video -->
<section class="hero teaser" style="margin-top: 30px; margin-bottom: 10px;">
  <div class="container is-max-desktop" style="display: flex; justify-content: center; align-items: center; flex-direction: column; text-align: center; padding-bottom: 10px;">
    <div class="hero-body">
      <div style="position: relative; width: 80%; padding-bottom: 45%; height: 0; margin-bottom: 20px;">
        <iframe src="https://www.youtube.com/embed/DnFVbwHeAtw"
                frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen
                style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
        </iframe>
      </div>
      <p class="subtitle" style="text-align: left; max-width: 80%; margin: 0 auto;">
        A short podcast about the paper
      </p>
    </div>
  </div>
</section>


  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image Section for "Our Task" -->
<section class="image-section" style="margin-top: 100px;">
  <div class="container is-max-desktop" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
    <h2 class="title is-3">Problem Formulation</h2>
    <img src="static/images/dataset_example.jpeg" alt="Website" style="max-width: 80%; height: auto; margin-bottom: 30px;"> <!-- Increased margin-bottom -->
    <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
      We demonstrate our ideas in the domain of Euclidean geometry. Our input is a geometry problem, described in both natural language and via a formal representation. The description includes the geometric entities involved (e.g., lines, angles), their relationships (e.g., perpendicular, collinear), and measurements or algebraic expressions over them. We also receive a <b>goal</b>, some quantity to be determined (e.g., the length of a line). In addition, the model has access to a dictionary of theorems that may be used in the proof. The output is a formal proof that derives the goal from the given conditions and theorems, along with the final, numeric answer. The proof consists of steps, each applying a specific theorem from the dictionary.
    </p>
  </div>
</section>



<!-- Image Section for "Our Task" -->
<section class="image-section" style="margin-top: 100px;">
  <div class="container is-max-desktop" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
    <h2 class="title is-3">Approach</h2>
    <img src="static/images/GeometryLLMPipeline.jpeg" alt="Website" style="max-width: 80%; height: auto; margin-bottom: 30px;"> <!-- Increased margin-bottom -->
    <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
      <b>Our neuro-symbolic approach.</b> Given a target problem from the FormalGeo-7k dataset, we first convert it into an <b>abstract form</b> by replacing entity names (e.g., lines, angles) and specific numeric values with placeholders. We then <b>retrieve structurally similar problems</b> from the abstracted dataset by computing Jaccard similarity over key formal components: <b>construction</b> (entities and geometric relations), <b>conditions</b> (e.g., angle equalities, segment lengths), and <b>goal</b> (the conclusion to be proven). This is based on the observation that structurally similar problems often share proof patterns. The retrieved problems, along with their corresponding formal proofs, are presented to an LLM as <b>in-context examples</b>, together with the available theorems from the Geometry Theorem Dictionary, to guide <b>proof generation</b> for the target problem. Finally, a <b>symbolic verifier</b> iteratively checks the generated proof and provides feedback until a correct proof is produced or a retry limit is reached.
    </p>
  </div>
</section>

<!--&lt;!&ndash; Image Section for "Our Distillation Framework" &ndash;&gt;-->
<!--<section class="image-section" style="margin-top: 100px;"> &lt;!&ndash; Adjusted margin-top &ndash;&gt;-->
<!--  <div class="container is-max-desktop" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">-->
<!--    <h2 class="title is-3">Dataset</h2>-->
<!--    <img src="static/images/dataset_example.jpg" alt="Website" style="max-width: 80%; height: auto; margin-bottom: 30px;"> &lt;!&ndash; Increased margin-bottom &ndash;&gt;-->
<!--    <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">-->
<!--      An example of a problem from the FormalGeo-7k dataset (Level 3). Left: Problem inputs, including a natural language description and formal representations &#45;&#45; construction (entities and relations), extended construction (inferred shapes and conditions based on extension rules, such as Angle(ECA) = Angle(ACE)), conditions (e.g., angle measures), and goal (the conclusion to be proven). Each problem also includes both a numeric answer (or expression) and a formal proof. A proof is composed of steps, each invoking a specific theorem from the dictionary. Right: The Geometry Theorem Dictionary, which defines available theorems (including required arguments and variation id). The full dataset also includes diagrams, but we do not use them here.-->
<!--    </p>-->
<!--  </div>-->
<!--</section>-->





<!-- Image carousel -->
<section class="hero is-small" style="margin-top: 150px;">
  <div class="hero-body" style="display: flex; justify-content: center; align-items: center;">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" style="display: flex; justify-content: center; align-items: center;">
        <div class="item" style="text-align: center;">
          <h2 class="title is-3">Experiments</h2>
          <img src="static/images/Experiments.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
            % correct proofs per level of difficulty (50 samples, 10 per level). Our analogy-based method outperforms the o1 base model (non-analogy) in all settings. Analogy retrieval, verifier feedback, and multiple runs each significantly contributes to performance. Our full pipeline (blue triangle) outperforms the baseline in every level, reaching an average aggregated accuracy of 80%. Even without multiple runs (blue square), performance remains strong at 68%, far exceeding the 10% of the base model baseline (red hollow circle).
          </p>
        </div>
        <div class="item" style="text-align: center;">
          <img src="static/images/average_runs_retries.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
            Average number of retries (top) and runs (bottom) per problem by difficulty level. The dashed line represents maximum allowed. Our analogy-based method consistently outperforms the base model, with fewer retries and runs across all levels.
          </p>
        </div>
        <div class="item" style="text-align: center;">
          <img src="static/images/ErrorDist.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
             Error distribution by tier for our method vs. the base model. Our method reduces errors across all tiers, with tier-1 errors being most frequent in both.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<!--  &lt;!&ndash; Youtube video &ndash;&gt;-->
<!--  <section class="hero is-small is-light" style="margin-top: 100px;">-->
<!--    <div class="hero-body">-->
<!--      <div class="container">-->
<!--        <h2 class="title is-3">Lightricks Real Use-case: Visual Editing with LLM-based Tool Chaining</h2>-->
<!--        <div class="columns is-centered has-text-centered">-->
<!--          <div class="column is-four-fifths">-->
<!--            <div class="publication-video">-->
<!--              <iframe src="https://www.youtube.com/embed/XWM7MM4M2Ws" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--            </div>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--  &lt;!&ndash; End youtube video &ndash;&gt;-->

<!--  <section class="hero is-small is-light">-->
<!--    <div class="hero-body">-->
<!--      <div class="container">-->
<!--        <h2 class="title">EMNLP 2024 Poster</h2>-->
<!--        <iframe src="static/pdfs/AIRecolorPoster.pdf" width="100%" height="550"></iframe>-->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->

  <!-- BibTex citation -->
  <section class="section" id="BibTeX" style="margin-top: 100px;">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sultan2025towards,
  title={Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach},
  author={Sultan, Oren and Stern, Eitan and Shahaf, Dafna},
  journal={arXiv preprint arXiv:2505.14479},
  year={2025}
}</code></pre>
  </div>
</section>

  <!-- End BibTeX citation -->

<!--  <footer class="footer">-->
<!--    <div class="container">-->
<!--      <div class="columns is-centered">-->
<!--        <div class="column is-8">-->
<!--          <div class="content">-->
<!--            <p>-->
<!--              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.-->
<!--              <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative-->
<!--              Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--            </p>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </footer>-->

  <!-- Statcounter tracking code -->
  <script type="text/javascript">
  var sc_project=12822541;
  var sc_invisible=1;
  var sc_security="46936e0e";
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img class="statcounter"
  src="https://c.statcounter.com/12822541/0/46936e0e/1/" alt="Web Analytics"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
  <!-- End of Statcounter Code -->

</body>
</html>
